{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MolSim 2020: ML for Gas Adsorption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will build a model that can predict the CO$_2$ uptake of metal-organic frameworks (MOFs), which are crystalline materials consisting of inorganic metal nodes linked by organic linkers.\n",
    "\n",
    "![MOF building principle](_static/mof_building_principle.png)\n",
    "\n",
    "There are two main **learning goals** for this exercise: \n",
    "1. Understand the typical workflow for machine learning in materials science. We will cover exploratory data analysis (EDA) and supervised learning (KRR).\n",
    "2. Learn about some Python packages that are useful for data analysis and visualization. If you are not already familiar with Python, this exercise can be a great opportunity to learn some basics.\n",
    "\n",
    "At the end of the exercise, you will produce an interactive plot like the one below, comparing the predictions of your model against CO$_2$ computed with GCMC simulations.\n",
    "The histograms show the distributions of the errors on the training set (left) and on the test set (right).\n",
    "\n",
    "![Parity interactive](_static/result.gif)\n",
    "\n",
    "This exercise requires a basic knowledge of Python, e.g. that you can write list comprehensions, and are able to read documentation of functions provided by Python packages.\n",
    "You will be asked to provide some function arguments (indicated by `#fillme` comments).\n",
    "\n",
    "If you struggle with this, click on the provided hints and/or partner up with someone more experienced. \n",
    "For those who already have experience with both Python and machine learning, there are also several optional exercises at the end.\n",
    "\n",
    "You can execute all the following code cells by pressing SHIFT and ENTER and get informations about the functions by pressing TAB when you are between the parentheses (see the notes for more tips). Also the [sklearn documentation](https://scikit-learn.org/stable/user_guide.html) is a great source of reference with many explanations and examples.\n",
    "\n",
    "In pandas dataframe (df) you can select columns using their name by running `df[columnname]`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -1. Only if you run on Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use this notebook on Colab, please uncomment the lines below (remove the `#`) and execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pandas pandas-profiling sklearn holoviews bokeh plotly matplotlib\n",
    "#!wget https://raw.githubusercontent.com/kjappelbaum/ml_molsim2020/master/descriptornames.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import packages we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics \n",
    "import os \n",
    "import numpy as np \n",
    "import pprint as pp\n",
    "\n",
    "# data\n",
    "import pandas as pd \n",
    "import pandas_profiling\n",
    "\n",
    "# machine learning \n",
    "# scaling of data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# model selection \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# model\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "# pipeline \n",
    "from sklearn.pipeline import Pipeline\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "# Dummy model\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "# Variance Threshold \n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "# metrics \n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             mean_absolute_error, mean_squared_error, max_error)\n",
    "# feature names\n",
    "from descriptornames import * \n",
    "\n",
    "# save/load models \n",
    "import joblib\n",
    "\n",
    "# For the permutation importance implementation\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from sklearn.metrics import check_scoring\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils import check_array\n",
    "\n",
    "# plotting \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "\n",
    "# for interactive plots, you can try to use holoviewes\n",
    "import holoviews as hv\n",
    "from holoviews import dim, opts\n",
    "hv.extension('plotly', 'bokeh', 'matplotlib')\n",
    "\n",
    "RANDOM_SEED = 4242424242\n",
    "DATA_DIR = 'data'\n",
    "DATA_FILE = os.path.join(DATA_DIR, 'data.csv')\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def view_structure(name):\n",
    "    import webbrowser\n",
    "    webbrowser.open(f'https://discover.materialscloud.org/mofs/detail?name={name}', new=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short question}}$\n",
    "- We declared a global variable to fix the random seed (`RANDOM_SEED`). Why did we do this?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first few rows to see if everythings seems reasonable ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li>Use something like <code>pd.options.display.max_columns=10</code> to adjust how many columns are shown.</li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also get some basic information ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short question}}$\n",
    "- How many materials are in the dataset? \n",
    "- Which datatypes do we deal with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define three global variables (hence upper case), which are the names of our feature and target columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'pure_uptake_CO2_298.00_1600000' \n",
    "TARGET_BINARY = 'target_binned'  # will be created later\n",
    "FEATURES = (geometric_descriptors + summed_functionalgroup_descriptors \n",
    "            + summed_linker_descriptors + summed_metalcenter_descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As descriptors we will use geometric properties such as density, pore volume, etc. and [revised autocorrelation functions](https://pubs.acs.org/doi/abs/10.1021/acs.jpca.7b08750) (RACs) that have been optimized for describing inorganic compounds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples for pore geometry descriptors (in `geometric_descriptors`) include: $D_i$ (the size of the largest included sphere), $D_f$ (the largest free sphere), and $D_{if}$ (the largest included free sphere) along the pore $-$ three ways of characterizing pore size. \n",
    "![pore diameters](_static/spheres.png)\n",
    "\n",
    "Also included are the surface area (SA) of the pore, and the probe-occupiable pore volume (POV).\n",
    "More details on the description of pore geometries can be found in [Ongari et al.](https://pubs.acs.org/doi/abs/10.1021/acs.langmuir.7b01682)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RACs (in the lists starting with `summed_...`) operate on the structure graph and encode information about the metal center, linkers and the functional groups as differences or products of heuristics that are relevant for inorganic chemistry, such as electronegativity ($\\chi$), connectivity ($T$), identity ($I$), covalent radii ($S$), and nuclear charge ($Z$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RACs scheme from the lecture](_static/racs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number in the descriptornames shows the coordination shell that was considered in the calculation of the RACs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target we use for this application is the high-pressure CO$_2$ uptake. This is the amount of CO$_2$ (mmol) the MOF can load per gram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split our data into a training set and a test set.\n",
    "\n",
    "In order to prevent *any* information of the test set from leaking into our model, we split *before* starting to analyze or transform our data. For more details on why this matters, see [chapter 7.10.2 of Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn//printings/ESLII_print10.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Split with stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, our model should perform well both on high-performing materials and on low-performing materials.\n",
    "If there is a large imbalance between the number of high-performing and low-performing materials in the data set (e.g. few good materials), we might end up with almost no good materials in the test data set.\n",
    "\n",
    "[Stratification](https://en.wikipedia.org/wiki/Stratified_sampling) ensures that the class distributions (ratio of good to bad materials) are the same in the training and test set.\n",
    "\n",
    "For stratification to work, we to define what makes a good or a bad material. Following [Boyd et al.](https://www.nature.com/articles/s41586-019-1798-7), we will use 2 mmol CO$_2$ / g as the threshold for the uptake, thus binarizing our continuous target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    " - add a column 'target_binary' that encodes whether a material is low performing (`0`) or high perfoming (`1`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li> you can use <a href='https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html'>pd.cut</a>, \n",
    "    <a href='https://stackoverflow.com/questions/4406389/if-else-in-a-list-comprehension'>list comprehension</a>, the <a href='https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer'> binarizer in sklearn </a>...) </li>\n",
    "    <li> a list comprehension example: <code> [1 if value > THRESHOLD else 0 for value in df[TARGET]] </code> </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 2 # in units of mmol CO2/g\n",
    "df['target_binned'] = # add your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform the actual split into training and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- select reasonable values for XX and XY and then perform the test/train splits. What do you consider when making this decision? \n",
    "\n",
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li>The size can either be integers or---easier---decimals like 0.1</li>\n",
    "    <li>When you perform the split into training and test set you need to trade-off bias (pessimistic bias due to little training data) and variance (due to little test data) </li>\n",
    "    <li>A typical split cloud be 70/30 </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_stratified, df_test_stratified = train_test_split(df, train_size=XX, \n",
    "                                                                test_size=XY, \n",
    "                                                                random_state=RANDOM_SEED, \n",
    "                                                                stratify=df['target_binned']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory data analysis (EDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have put the test set aside, we can give the training set a closer look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Get some description of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [`pandas_profiling`](https://github.com/pandas-profiling/pandas-profiling) package to get an overview of the data.\n",
    "\n",
    "$\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Are there skewed distributions? \n",
    "- Are there missing values? \n",
    "- What are other issues with the dataset that you might want to fix before training a model?\n",
    "- How could one fix those issues?\n",
    "\n",
    "By default, `pandas_profiling` computes many statistics, which can take some time. For this reason, we use the `minimal=True` option, which disables the calculation of correlations and dynamic binning.\n",
    "You can speed it up even more by subsampling the data first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li> use <code>df.sample(500)</code> to get a random sample of 500 rows, e.g. <code>df_train_stratified.sample(500)</code>. </li>\n",
    "    <li> the function call might then look like <code>pandas_profiling.ProfileReport(df_train_stratified.sample(500))</code> </li>\n",
    "</ul>\n",
    "</details>\n",
    "\n",
    "You can use `profile.to_file(output_file=\"your_report.html\")` to save the report to an HTML file, which can be needed if you run this exercise on Google Colab. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pandas_profiling.ProfileReport(#fillme, minimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Plot some features against the target property and calculate the Pearson and Spearman correlation coefficient (what is the different between those?) \n",
    "- What are the strongest correlations? \n",
    "- *Optional:* Do they change if you switch from CO$_2$ to CH$_4$ uptake as the target instead? Explain your observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the correlation matrices, you can use the `df.corr(method=)`method on your dataframe (`df`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li> To get the correlation with a target, you can use indexing. E.g. <code>df.corr(method='spearman')[TARGET]</code></li>\n",
    "    <li> To sort numpy arrays, use <code>.sort()</code> </li>\n",
    "      <li> You can use <code>scatter = hv.Scatter(gaussian_mix, 'x', ['y', 'color']).opts(color='color', cmap='rainbow')</code> for plotting </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkRed}{\\textsf{Tip}}$\n",
    " \n",
    "The atomic structures of the MOFs have been deposited on the [Materials Cloud](https://www.materialscloud.org/discover/mofs#mcloudHeader). \n",
    "You can use the identifier from the \"MOFname\" column to visualize the structure of any material directly from the notebook via the `view_structure` function. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_structure('str_m2_o10_o29_pcu_sym.69')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For machine learning, it is important to have some *baselines* to which one then compares the results of a model. \n",
    "\n",
    "A baseline could be a really simple model, a basic heuristic or the current state of the art.\n",
    "this. We will use a heuristic.\n",
    "\n",
    "For this we use sklearn `Dummy` objects that simply calculate the mean, the median or the most frequent case of the training set, when you run the `fit()` method on them (which takes the features matrix $\\mathbf{X}$ and the labels $\\mathbf{y}$ as arguments.\n",
    "I.e., the prediction of a `DummyRegressor` with `mean` strategy will always be the mean, independent of the input. \n",
    "\n",
    "Using these objects, instead of the mean directly, allows you to easily swap them with other models in pipelines, where one chains many data transformation steps (see section 6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Build dummy models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Create [`DummyRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html) instances for  `mean`, `median`. (e.g. `dummyinstance = DummyRegressor(strategy='')`)\n",
    "- Train them on the training data (`dummyinstance.fit(df_train[FEATURES], df_train[TARGET_BINARY])`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints</font></summary>\n",
    "<ul>\n",
    "    <li> to create <code>DummyRegressor</code> you can for example use <code> dummyregressor_mean = DummyRegressor(strategy='mean') </code> </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DummyRegressors\n",
    "dummyregressor_mean = DummyRegressor(strategy='mean')\n",
    "dummyregressor_median = DummyRegressor(#fillme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Dummy Regressors\n",
    "dummyregressor_mean.fit(df_train_stratified[FEATURES], df_train_stratified[TARGET])\n",
    "dummyregressor_median.fit(#fillme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the performance of the dummy models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Calculate maximum error, mean absolute error and mean square error for the dummy regressors on training and test set. What would you expect those numbers to be?\n",
    "- Do the actual values surprise you? \n",
    "- What does this mean in practice for reporting of metrics?\n",
    "\n",
    "It can be handy to store our metrics of choice in a nested dictionary: \n",
    "\n",
    "```python\n",
    "{'dummyestimator1': {\n",
    "                        'metric_a_key': metric_a_value, \n",
    "                        'metric_b_key': metric_b_value\n",
    "                    },\n",
    " 'dummyestimator2': {\n",
    "                        'metric_a_key': metric_a_value, \n",
    "                        'metric_b_key': metric_b_value\n",
    "                    },\n",
    " }\n",
    "``` \n",
    "\n",
    "You will now write functions `get_regression_metrics(model, X, y_true)` that compute the metrics and return the dictionary for a given model. The `predict` method takes the feature matrix $\\mathbf{X}$ as input.\n",
    "\n",
    "In them, we calculate \n",
    "\n",
    "$\\mathrm {MAE} =\\frac{\\sum _{i=1}^{n}\\left|Y_{i}-\\hat{y}_{i}\\right|}{n}.$\n",
    "\n",
    "and \n",
    "\n",
    "$\\mathrm {MSE} = {\\frac {1}{n}}\\sum _{i=1}^{n}(Y_{i}-{\\hat {Y_{i}}})^{2}.$ \n",
    "\n",
    "as well as the maximum error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints</font></summary>\n",
    "<ul>\n",
    "    <li> to perform a prediction using a estimator object, you can call <code> classifier.predict(X) </code> </li>\n",
    "    <li> to calculate metrics, you can for example call <code>accuracy_score(true_values, predicted_values) </code> </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_metrics(model, X, y_true): \n",
    "    \"\"\"\n",
    "    Get a dicionary with regression metrics:\n",
    "    \n",
    "    model: sklearn model with predict method\n",
    "    X: feature matrix\n",
    "    y_true: ground truth labels (predicted values)\n",
    "    \"\"\"\n",
    "    y_predicted = model.predict(#fillme)\n",
    "    \n",
    "    mae = mean_absolute_error(#fillme)\n",
    "    mse = mean_squared_error(#fillme)\n",
    "    maximum_error = max_error(#fillme)\n",
    "    \n",
    "    metrics_dict = {\n",
    "        'mae': mae, \n",
    "        'mse': mse, \n",
    "        'max_error': maximum_error\n",
    "    }\n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_regressors = [\n",
    "    ('mean', dummyregressor_mean), \n",
    "    ('median', dummyregressor_median)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_regressor_results_test = {} # initialize empty dictionary\n",
    "dummy_regressor_results_train = {}\n",
    "for regressorname, regressor in dummy_regressors: \n",
    "    dummy_regressor_results_test[regressorname] = get_regression_metrics(#fillme)\n",
    "    dummy_regressor_results_train[regressorname] = get_regression_metrics(#fillme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build actual regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a simple kernel ridge regression (KRR) machine learning model and train it with our raw data.\n",
    "You can try different kernels, but we recommend to start with the Gaussian radial basis function ('rbf') kernel.\n",
    " \n",
    " $\\color{DarkBlue}{\\textsf{Short Question}}$\n",
    "- Do you expect this model to perform better than the dummy models?\n",
    "- Train it and then calculate the performance metrics on the training and test set. How do they compare to the performance of the dummy models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "krr = KernelRidge(kernel='rbf')\n",
    "krr.fit(#fillme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the metrics on the train and the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the model performance in detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have trained our first machine learning model!\n",
    "We'll first have a closer look at its performance, before learning how to improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Create a parity plot (true values against predictions)for the training and test data\n",
    "- plot a histogram of the distribution of the training and test errors on the training and test set. Plot the errors also as a function of the true value\n",
    "- Let's assume we would like to use our model for pre-screening a library of millions of porous materials to zoom-in on those with the most promising gas uptake. Could you tolerate the errors of your model?\n",
    "- compare the parity plots for this model with the ones for the dummy models. \n",
    "Use the plotting functions below the evaluate all the following models you train.\n",
    "\n",
    "For this exercise, it can be handy to save the results in a dictionary, e.g. \n",
    "```(python)\n",
    "res_train = {\n",
    "    'y true': ,\n",
    "    'y pred': \n",
    "}\n",
    "```\n",
    "\n",
    "As you will need to run this multiple times, it can be useful to make a function that can create such a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints for plotting</font></summary>\n",
    "<ul>\n",
    "    <li> If you want to use matplotlib, you can use the <a href=\"https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.hist2d.html\">hist2d function</a> </li>\n",
    "    <li>to create the frequencies and the edges of a histogram, one can use <code>np.histogram</code></li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries with training and test results \n",
    "res_train = {\n",
    "    'y true': # fillme,\n",
    "    'y pred': # fillme\n",
    "}\n",
    "\n",
    "res_test = {\n",
    "    'y true': # fillme,\n",
    "    'y pred': # fillme\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train['error'] = res_train['y true'] - res_train['y pred']\n",
    "res_test['error'] = res_test['y true'] - res_test['y pred']\n",
    "\n",
    "# plot it\n",
    "hv.extension('bokeh')\n",
    "hex_train = hv.HexTiles(res_train, ['y true', 'y pred']).hist(dimension=['y true','y pred'])\n",
    "hex_test = hv.HexTiles(res_test, ['y true', 'y pred']).hist(dimension=['y true', 'y pred'])\n",
    "hex_train + hex_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set still has a couple of issues you might have noticed:\n",
    "- The feature values are not scaled (different features are measured in different units ...)\n",
    "- Some features are basically constant, i.e. do not contain relevant information and just artificually increase the dimensionality of the problem \n",
    "- Some feature distributions are skewed (which is more relevant for some models than for others ...)\n",
    "- There are only few good materials (also the target distribution is skewed), so if we weight all materials equally we might not do a good job in predicting the best materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Standard scaling and building a first pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we will now go beyond training a single model, we will build [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), which are objects that can collect a selection of transformations and estimators. This makes it quite easy to apply the same set of operations to different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Build a pipline that first performs standard scaling and then a KRR. Call it `pipe_w_scaling`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints</font></summary>\n",
    "<ul>\n",
    "    <li> the <code>fit</code>, <code>predict</code> methods also work for pipelines </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_w_scaling = Pipeline(\n",
    "   [\n",
    "       ('scaling', StandardScaler()), \n",
    "       ('krr', #fillme)\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most approach to hyperparameter optimization is to define a grid of all relevant parameters and to search over the grid for the best model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Think about which parameters you could optimize in the pipeline. Note that your KRR model has parameters you can optimize. You can also switch off some steps by setting them to `None'.\n",
    "- For each parameter you need to define a resonable grid to search over.\n",
    "- Run the hyperparameter optimization using 5-fold cross-validation (you can adjust the number of folds according to your computational resources/impatience. It turns out at k=10 is the [best tradeoff between variance and bias](https://arxiv.org/abs/1811.12808)). \n",
    "Tune the hyperparameters until you are statisfied (e.g., until you cannot improve the cross validated error any more)\n",
    "- Why don't we use the test set for hyperparameter tuning? \n",
    "- Evaluate the model performance by calculating the performance metrics (MAE, MSE, max error) on the training and the test set.\n",
    "- Instead of grid search, try to use random search on the same grid (`RandomizedSearchCV`) and fix the number of evaluations (`n_iter`) to a fraction of the number of evaluations of grid search. What do you observe and conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkRed}{\\textsf{Tips}}$\n",
    "- If you want to see what is happening, set the verbosity argument of the `GridSearchCV` object to a higher number.\n",
    " \n",
    "- If you want to speed up the optimization, you can run it in parallel by setting the `n_jobs` argument to the number of workers. If you set it to -1 it will use all available cores.\n",
    " \n",
    "- If the optimization is too slow, reduce the number of data points in your set, the number of folds or the grid size. Note that it can also be a feasible strategy to first use a coarser grid and the a finer grid for fine-tuning.\n",
    "\n",
    "- For grid search, you need to define a parameter grid, which is a dictionary of the following form: \n",
    "```(python)\n",
    "param_grid = {\n",
    "                    'pipelinestage__parameter': np.logspace(-4,1,10),\n",
    "                    'pipelinestage': [None, TransformerA(), TransformerB()]\n",
    "            }\n",
    "```\n",
    "\n",
    "- After the search, you can access the best model with `.best_estimator_` and the best parameters with `.best_params_` on the GridSearchCV instance\n",
    "\n",
    "- If you initialize the GridSearchCV instance with `refit=True` it will automatically train the model with all training data (and not only the training folds from cross-validations)\n",
    "\n",
    "The double underscore (dunder) notation works recursively and specifies the parameters for any pipeline stage. For example, `ovasvm__estimator__cls__C` would specifiy the `C` parameter of the estimator in the one-versus-rest classifier. \n",
    "\n",
    "You can print all parameters of the pieline using `pp.pprint(sorted(pipeline.get_params().keys()))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints about pipelines and grid search</font></summary>\n",
    "<ul>\n",
    "    <li> You can use the <code>np.logspace</code> function to generate a grid for values that you want to vary on a logarithmic scale </li>\n",
    "    <li> There are two hyperparameters for KRR: the regularization strength <code>alpha</code> and the Gaussian width  <code>gamma</code> </li>\n",
    "    <li> For the regularization strength, values between 1 and 1e-3 can be reasonable. For gamma you can use the median heuristic, gamma = 1 / median, or values between 1e-3 and 1e3</li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid and the grid search object\n",
    "param_grid = {\n",
    "                    'scaling': [MinMaxScaler(), StandardScaler()],\n",
    "                    'krr__alpha': #fillme,\n",
    "                    'krr__#fillme': #fillme\n",
    "            }\n",
    "\n",
    "grid_krr = GridSearchCV(#your pipeline, param_grid=param_grid, \n",
    "                        cv=#number of folds, verbose=2, n_jobs=-1)\n",
    "\n",
    "random_krr = RandomizedSearchCV(#your pipeline, param_distributions=param_grid, n_iter=#number of evaluations,\n",
    "                        cv=#number of folds, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the grid search by calling the fit method \n",
    "grid_krr.fit(#fillme)\n",
    "random_krr.fit(#fillme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the performance metrics\n",
    "get_regression_metrics(#fillme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for some more information about hyperparameter optimization</font></summary>\n",
    "Grid search is not the most efficient way to perform hyperparamter optimization. Even <a href=\"http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf\">random search was shown to be more efficient</a>. Really efficient though are Bayesian optimization approaches like <a href='https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf)'>TPE</a>. This is implemented in the hyperopt library, which is also installed in your conda environment.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hyperparameter optimization with hyperopt (advanded and optional outlook)</font></summary>\n",
    "    \n",
    "<b>Import the tools we need</b>\n",
    "<code>\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, mix, rand, anneal, space_eval\n",
    "from functools import partial\n",
    "</code>    \n",
    "\n",
    "<b>Define the grid</b>\n",
    "<code>\n",
    "param_hyperopt = {\n",
    "    \"krr__alpha\": hp.loguniform(\"krr__alpha\", np.log(0.001), np.log(10)),\n",
    "    \"krr__gamma\": hp.loguniform(\"krr__gamma\", np.log(0.001), np.log(10)),\n",
    "}\n",
    "</code> \n",
    "\n",
    "<b>Define the objective function</b>\n",
    "<code>\n",
    "def objective_function(params):\n",
    "    pipe.set_params(\n",
    "        **{\n",
    "            \"krr__alpha\": params[\"krr__alpha\"],\n",
    "            \"krr__gamma\": params[\"krr__gamma\"],\n",
    "        }\n",
    "    )\n",
    "    score = cross_val_score(\n",
    "        pipe, X_train, y_train, cv=10, scoring=\"neg_mean_absolute_error\"\n",
    "    ).mean()\n",
    "    return {\"loss\": -score, \"status\": STATUS_OK} \n",
    "</code>\n",
    "\n",
    "<b>We will use a search in which we mix random search, annealing and tpe</b>\n",
    "<code>\n",
    "trials = Trials()\n",
    "mix_search = partial(\n",
    "   mix.suggest,\n",
    "   p_suggest=[(0.15, rand.suggest), (0.15, anneal.suggest), (0.7, tpe.suggest)],\n",
    ")\n",
    "</code>\n",
    "\n",
    "<b>Now, we can minimize the objective function.</b>\n",
    "<code>\n",
    "best_param = fmin(\n",
    "        objective_function,\n",
    "        param_hyperopt,\n",
    "        algo=mix_search,\n",
    "        max_evals=MAX_EVALES,\n",
    "        trials=trials,\n",
    "        rstate=np.random.RandomState(RANDOM_SEED),\n",
    "    )\n",
    "</code>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Submit your results to Kaggle (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the [Kaggle competition](http://www.kaggle.com/c/molsim2020) for this course! There we deposited some features that you have not seen before. Use your model to predict the CO$_2$ uptake for the structures there. Tune your model to get the best predictions as you move trough this notebook! Also feel free to explore other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `submission.csv` with your predictions to join the competition and upload it to the competition site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_data = pd.read_csv('data/features.csv')\n",
    "kaggle_predictions = #fillme.predict(kaggle_data[FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": kaggle_data[\"id\"],\n",
    "    \"prediction\": kaggle_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have created this file, you can had over to the [submission page](https://www.kaggle.com/c/molsim2020/submit) and upload your file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kaggle submission](_static/kaggle_upload.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we would like to remove features with low variance. This can be done by setting a variance threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Add a variance threshold to the pipeline (select the correct function argument)\n",
    "- Use random search for hyperparameter optimization, retrain the pipeline, and calculate the performance metrics (max error, MAE, MSE) on the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipe_variance_threshold = Pipeline(\n",
    "    # fillme with the pipeline steps\n",
    "    [\n",
    "        ('variance_treshold', VarianceThreshold(#fillme with threshold)), \n",
    "        #fillme with remaining pipeline steps\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_variance_threshold = {\n",
    "                    'scaling__parameter': [None, StandardScaler()],\n",
    "                    'krr__alpha': #fillme,\n",
    "                    'krr__#fillme': #fillme,\n",
    "                    'variance_treshold__threshold': #fillme\n",
    "            }\n",
    "\n",
    "random_variance_treshold = RandomizedSearchCV(#your pipeline, param_distributions=param_grid, n_iter=#number of evaluations,\n",
    "                        cv=#number of folds, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline and run the evaluation\n",
    "random_variance_treshold.fit(#fillme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short Exercise (optional)}}$\n",
    "- replace the variance threshold with a model-based feature selection \n",
    "`('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\")))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we spent so much time in optimizing our model, we do not want to loose it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- use the [joblib library](https://scikit-learn.org/stable/modules/model_persistence.html) to save your model\n",
    "- make sure you can load it again\n",
    "\n",
    "Use this to save models as you go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump your model\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load it again\n",
    "model_loaded = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Influence of Regularization (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- what happens if you set $\\alpha=0$ or to large value? Why is this the case?\n",
    "\n",
    " To test this, fix this value in one of your pipelines, retrain the models (re-optimizing the other hyperparameters) and rerun the performance evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints</font></summary>\n",
    "<ul>\n",
    "    <li> Check the derivation for ridge regression and KRR in the notes. </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Interpreting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that our model performs decently, we would like to know which features are mainly responsible for this, i.e. how the model performs its reasoning. \n",
    "\n",
    "One method to do so is the [permutation feature importance technique](https://christophm.github.io/interpretable-ml-book/feature-importance.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short question}}$\n",
    "\n",
    "We use both descriptors that encode the pore geometry (density, pore diameters, surface areas) as well as some that describe the chemistry of the MOF (the RACs). \n",
    "- Would you expect the relative importance of these features to be different for prediction of gas adsorption at high vs low gas pressure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li> <a href=\"https://pubs.acs.org/doi/abs/10.1021/acs.chemmater.8b02257\">An article from Diego et al.</a> (10.1021/acs.chemmater.8b02257) gives some hints.</li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Complete the function `_calculate_permutation_scores` (which we took from the `sklearn` package) and which is needed to calculate the permutation feature importance using the `permutation_importance` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_permutation_scores(estimator, X, y, col_idx, random_state,\n",
    "                                  n_repeats, scorer):\n",
    "    \"\"\"Calculate score when `col_idx` is permuted. Based on the sklearn implementation\n",
    "    \n",
    "    estimator: sklearn estimator object\n",
    "    X: pd.Dataframe or np.array\n",
    "    y: pd.Dataframe or np.array\n",
    "    col_idx: int\n",
    "    random_state: int\n",
    "    n_repeats: int \n",
    "    scorer: function that takes model, X and y_true as arguments\n",
    "    \"\"\"\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    X_permuted = X.copy()\n",
    "    scores = np.zeros(n_repeats)\n",
    "    # get the indices\n",
    "    shuffling_idx = np.arange(X.shape[0])\n",
    "    for n_round in range(n_repeats):\n",
    "        # shuffle them (fill in what you want to shuffle)\n",
    "        random_state.shuffle(#fillme)  \n",
    "        \n",
    "        # Deal with dataframes\n",
    "        if hasattr(X_permuted, \"iloc\"):\n",
    "            # .iloc selects the indices from a dataframe and yougive it [row, column]\n",
    "            col = X_permuted.iloc[#fillme]\n",
    "            col.index = X_permuted.index\n",
    "            X_permuted.iloc[:, col_idx] = col\n",
    "            \n",
    "        # Deal with numpy arrays \n",
    "        else:\n",
    "            # array indexing is [row, column]\n",
    "            X_permuted[:, col_idx] = X_permuted[#fillme]\n",
    "        \n",
    "        # Get the scores\n",
    "        feature_score = scorer(estimator, X_permuted, y)\n",
    "        \n",
    "        # record the scores in array \n",
    "        scores[n_round] = feature_score\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_importance(estimator, X, y, scoring='neg_mean_absolute_error', n_repeats=5,\n",
    "                           n_jobs=-1, random_state=None):\n",
    "    \"\"\"Permutation importance for feature evaluation \n",
    "    estimator : object\n",
    "        An estimator that has already been :term:`fitted` and is compatible\n",
    "        with :term:`scorer`.\n",
    "    X : ndarray or DataFrame, shape (n_samples, n_features)\n",
    "        Data on which permutation importance will be computed.\n",
    "    y : array-like or None, shape (n_samples, ) or (n_samples, n_classes)\n",
    "        Targets for supervised or `None` for unsupervised.\n",
    "    scoring : string, callable or None, default=None\n",
    "        Scorer to use. It can be a single\n",
    "        string (see :ref:`scoring_parameter`) or a callable (see\n",
    "        :ref:`scoring`). If None, the estimator's default scorer is used.\n",
    "    n_repeats : int, default=5\n",
    "        Number of times to permute a feature.\n",
    "    n_jobs : int or None, default=None\n",
    "        The number of jobs to use for the computation.\n",
    "        `None` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        `-1` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "    random_state : int, RandomState instance, or None, default=None\n",
    "        Pseudo-random number generator to control the permutations of each\n",
    "        feature. See :term:`random_state`.\n",
    "    \"\"\"\n",
    "    # Deal with dataframes\n",
    "    if not hasattr(X, \"iloc\"):\n",
    "        X = check_array(X, force_all_finite='allow-nan', dtype=None)\n",
    "\n",
    "    # Precompute random seed from the random state to be used\n",
    "    # to get a fresh independent RandomState instance for each\n",
    "    # parallel call to _calculate_permutation_scores, irrespective of\n",
    "    # the fact that variables are shared or not depending on the active\n",
    "    # joblib backend (sequential, thread-based or process-based).\n",
    "    random_state = check_random_state(random_state)\n",
    "    random_seed = random_state.randint(np.iinfo(np.int32).max + 1)\n",
    "     \n",
    "    # Determine scorer from user options.\n",
    "    scorer = check_scoring(estimator, scoring=scoring)\n",
    "    # get the performance score on the unpermuted data \n",
    "    baseline_score = scorer(estimator, X, y)\n",
    "    \n",
    "    # run the permuted evaluations in parallel for each column\n",
    "    scores = Parallel(n_jobs=n_jobs)(delayed(_calculate_permutation_scores)(\n",
    "        estimator, X, y, col_idx, random_seed, n_repeats, scorer\n",
    "    ) for col_idx in range(X.shape[1]))\n",
    "    \n",
    "    # get difference two\n",
    "    importances = baseline_score - np.array(scores)\n",
    "    \n",
    "    # return the results (dictionary)\n",
    "    return Bunch(importances_mean=np.mean(importances, axis=1),\n",
    "                 importances_std=np.std(importances, axis=1),\n",
    "                 importances=importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Use your function to find the five most important features.\n",
    "- Which are they? Did you expect this result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_results = permutation_importance(#fillme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_results['features'] = FEATURES\n",
    "bars = hv.Bars(permutation_results, 'features', ['importances_mean', 'importances_std']).sort('importances_mean', reverse=True)\n",
    "errors = hv.ErrorBars(permutation_results, 'features', vdims=['importances_mean', 'importances_std']).sort('importances_mean', reverse=True)\n",
    "\n",
    "bars * errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints</font></summary>\n",
    "<ul>\n",
    "    <li> To get the top <emph>n</emph> indices of an array <code>a</code>, you can use <code>np.argsort(a)[-n:]</code></li>\n",
    "    <li> Get the feature names from the <code>FEATURES</code> list </li> \n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for more information on model interpretation</font></summary>\n",
    "The permutation feature importance technique is not a silver bullet, e.g. there are issues with correlated features.\n",
    "However, it is likely <a href='https://explained.ai/rf-importance/'>a better choice than feature importance, like impurity decrease, derived from random forests</a>).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. PCA (optional) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, our data is high-dimensional (see `df_train.shape`). \n",
    "It's hard to visualize such data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- How many features did we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to visualize high dimensional data is to use [principal component analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) which helps you find those linear combinations of features that explain most of the variance in the data. \n",
    "But this method also has some caveats, which we will explore later in this exercise, and which non-linear techniques like [t-sne](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) try to avoid. \n",
    "\n",
    "One can then plot the data in two dimensions in terms of the first two principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- plot the explained variance as a function of the number of principal components and plot a [scree plot](https://en.wikipedia.org/wiki/Scree_plot). Use all features for this analysis (on the training set). Would it be possible to compress this dataset using PCA? \n",
    "- plot the dataset in terms of the first two principal components. What are the features that are most important in those first principal components (look at the loadings of the first two principal components). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li> A scree plot shows the explained variance as a function of the number of components. For this, we run <code>PCA(n_components=n_features)</code>, where <code>n_components=X.shape[1] </code> </li>\n",
    "    <li> The <code> PCA </code> object also has a <code> fit </code> method </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the PCA object and run it \n",
    "pca = PCA(n_components=#fillme)\n",
    "pca.fit(StandardScaler().fit_transform(df_train_stratified[#fillme]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scree plot\n",
    "data = {\n",
    "            'feature' : np.arange(0, len(#fillme)),\n",
    "            'explained variance ratio': pca.explained_variance_ratio_\n",
    "        }\n",
    "\n",
    "hv.Curve(data, 'feature', 'explained variance ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA on Swiss Roll  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data comes in interesting shapes. \n",
    "The Swiss roll dataset was created to test out \n",
    "dimensionality reduction algorithms by creating some data in 2D and mapping it then to 3D  using a smooth function (here: $(x,y,z) := (x \\cos (x), y, x \\sin(x))$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Create some Swiss roll data - first use the `gaussian_mixture_data` to create Gaussian mixture data in 2D, then map it to 3D using `map_to_3d`. \n",
    "- Visualize the data first in 2D and, after the mapping, in 3D. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li> Both <code>means</code> and <code>covariances</code> take lists as input.  </li>\n",
    "    <li> The list for the means contains tuples of (x,y) coordinates for the centers of the Gaussian blobs and the list for the covariances takes floats. </li>\n",
    "    <li> try e.g. <code> means = [(-2, -2), (-2,2), (2,-2), (2,2)], covariances = [1,1,1,1] </code> </li>\n",
    "    <li> for plotting in matplotlib you can use the <a href=\"https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.scatter.html\"><code>plt.scatter</code></a>. You can use the <code>c</code> argument to color the points.\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mixture_data(means: list=[(-2, -2), (1,1)], \n",
    "                          covariances: list=[1], numpoints: int=200) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    generate some gaussian mixture data\n",
    "    \"\"\"\n",
    "    from sklearn.datasets import make_gaussian_quantiles\n",
    "    assert len(means) == len(covariances)\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    c = []\n",
    "    \n",
    "    # loop over all means and covariances\n",
    "    for i, mucov in enumerate(zip(means, covariances)):\n",
    "        mu, cov = mucov\n",
    "        print(f'making blob of mean {mu} and covariance {cov}')\n",
    "        x, y = make_gaussian_quantiles(mean=mu, cov=cov,\n",
    "                                         n_samples=numpoints, \n",
    "                                         random_state=RANDOM_SEED)\n",
    "        X.append(x[:,0])\n",
    "        Y.append(x[:,1])\n",
    "        c.append([i  + 1] * numpoints)\n",
    "    \n",
    "    gaussian_mix = {\n",
    "        'x': np.array(X).flatten(),\n",
    "        'y': np.array(Y).flatten(),\n",
    "        'color': np.array(c).flatten() \n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame.from_dict(gaussian_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_mix = gaussian_mixture_data(##fillme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "scatter = hv.Scatter(gaussian_mix, 'x', ['y', 'color']).opts(color='color', cmap='rainbow')\n",
    "scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Map it to 3D and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_3d(x: float, y:float) -> list: \n",
    "    \"\"\"\n",
    "    x cos (x), y, x sin(x)\n",
    "    Feel free to play aroung with it\n",
    "    \"\"\"\n",
    "    return [.5 * x * np.cos(x), y,   2 * x * np.sin(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Replace `#fillme` by the correct function arguments in the list comprehension.\n",
    "- Plot the result in three dimensions using the 'color' column for coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = np.array([map_to_3d(#fillme) for x,y in zip(gaussian_mix['x'], gaussian_mix['y'])])\n",
    "\n",
    "gaussian_mix['x'] = coordinates[:,0]\n",
    "gaussian_mix['y'] = coordinates[:,1]\n",
    "gaussian_mix['z'] = coordinates[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data in 3d\n",
    "scatter3d = hv.Scatter3D(#fillme, kdims=['x', 'y'], vdims=['z', 'color'])\n",
    "scatter3d = scatter3d.opts(\n",
    "            opts.Scatter3D(color='color',  cmap='rainbow'))\n",
    "scatter3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the PCA transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's project the data from feature space onto its first two principal components, and then plot the data in two dimension in these coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Project the three dimensional swiss roll data onto the first two principal components\n",
    "- Plot the data in two dimensions, use the original coloring (which could e.g. represent different material classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li> To perform the the transformation, you can use the <code>fit_transform()</code> method of the <code>PCA(n_components=2)</code> instance</li>\n",
    "</ul>\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the PCa\n",
    "pca = PCA(#fillme)\n",
    "swissroll_transformed = pca.fit_transform(#fillme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "swissroll_transformed_dict = {}\n",
    "swissroll_transformed_dict['x'] = swissroll_transformed[:,#fill with a integer]\n",
    "swissroll_transformed_dict['y'] = swissroll_transformed[:,#fill with a integer]\n",
    "swissroll_transformed_dict['color'] = gaussian_mix['color']\n",
    "scatter = hv.Scatter(swissroll_transformed_dict, 'x', ['y', 'color']).opts(\n",
    "        color='color', cmap='rainbow')\n",
    "scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- If you look at the 2D-plot, what would you have expected a dimensionality reduction to do? What did actually happen? \n",
    "- What happens to the transformation if you scale one feature? What does it mean in practice when you e.g. want to understand the importance of features in terms of their variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li> To standardize one variable you can use <code>gaussian_mix['x'] = (gaussian_mix['x']- gaussian_mix['x'].mean())/gaussian_mix['x'].std()</code> - Or just try to multiply by a constant </li>\n",
    "    <li> For serious applications, always look at the data in the dataframe first... the same quantity might come in different units! </li>\n",
    "</ul>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional research questions (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change the target from CO$_2$ to methane. Is it easier to predict? What changes in the feature importance?\n",
    "- Do also a search over model space. Do you find better performance with a Gradient Boost model? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
